{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TD présente un algorithme pour calculer les coefficients d'une régression quantile et par extension d'une médiane dans un espace à plusieurs dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Précision : dans tout l'énoncé, la transposée d'une matrice est notée $X' = X^{T}$. La plupart du temps $X$ et $Y$ désignent des vecteurs colonnes. $\\beta$ désigne un vecteur ligne, $W$ une matrice diagonale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 \n",
    "\n",
    "A l'aide du module [random](https://docs.python.org/3/library/random.html), générer un ensemble de points aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "La médiane d'un ensemble de points $\\left\\{X_1, ..., X_n\\right\\}$ est une valeur $X_M$ telle que : \n",
    "\n",
    "$$\\sum_i \\mathbb{1}_{X_i < X_m} = \\sum_i \\mathbb{1}_{X_i > X_m}$$\n",
    "\n",
    "Autrement dit, il y a autant de valeurs inférieures que supérieures à $X_M$. On obtient cette valeur en triant les éléments par ordre croissant et en prenant celui du milieu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "Lorsque le nombre de points est pair, la médiane peut être n'importe quelle valeur dans un intervalle. Modifier votre fonction de façon à ce que la fonction précédente retourne le milieu de la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "Pour un ensemble de points $E=\\left\\{X_1, ..., X_n\\right\\}$, on considère la fonction suivante : \n",
    "\n",
    "$$f(x) = \\sum_{i=1}^n \\left | x - X_i\\right |$$.\n",
    "\n",
    "On suppose que la médiane $X_M$ de l'ensemble $E$ n'appartient pas à $E$ : $X_M \\notin E$. Que vaut $f'(X_M)$ ?\n",
    "On acceptera le fait que la médiane est le seul point dans ce cas.\n",
    "\n",
    "$$f'(X_m) = - \\sum_{i=1}^n \\mathbb{1}_{X_i < X_m} + \\sum_{i=1}^n \\mathbb{1}_{X_i > X_m}$$\n",
    "\n",
    "Par définition de la médiane, $f'(X_M)=0$. En triant les éléments, on montre que la $f'(x) = 0 \\Longleftrightarrow x=X_m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "On suppose qu'on dispose d'un ensemble d'observations $\\left(X_i, Y_i\\right)$ avec $X_i, Y_i \\in \\mathbb{R}$.\n",
    "La régression linéaire consiste une relation linéaire $Y_i = a X_i + b + \\epsilon_i$\n",
    "qui minimise la variance du bruit. On pose :\n",
    "\n",
    "$$E(a, b) = \\sum_i \\left(Y_i - (a X_i + b)\\right)^2$$\n",
    "\n",
    "On cherche $a, b$ tels que :\n",
    "\n",
    "$$a^*, b^* = \\arg \\min E(a, b) = \\arg \\min \\sum_i \\left(Y_i - (a X_i + b)\\right)^2$$\n",
    "\n",
    "La fonction est dérivable et on trouve :\n",
    "\n",
    "$$\\frac{\\partial E(a,b)}{\\partial a} = - 2 \\sum_i X_i ( Y_i - (a X_i + b)) \\text{ et } \\frac{\\partial E(a,b)}{\\partial b} = - 2 \\sum_i ( Y_i - (a X_i + b))$$\n",
    "\n",
    "Il suffit alors d'annuler les dérivées. On résoud un système d'équations linéaires. On note :\n",
    "\n",
    "$$\\begin{array}{l} \\mathbb{E} X = \\frac{1}{n}\\sum_{i=1}^n X_i \\text{ et } \\mathbb{E} Y = \\frac{1}{n}\\sum_{i=1}^n Y_i \\\\ \\mathbb{E}{X^2} = \\frac{1}{n}\\sum_{i=1}^n X_i^2 \\text{ et } \\mathbb{E} {XY} = \\frac{1}{n}\\sum_{i=1}^n X_i Y_i \\end{array}$$\n",
    "\n",
    "Finalement :\n",
    "\n",
    "$$\\begin{array}{l} a^* = \\frac{ \\mathbb{E} {XY} - \\mathbb{E} X \\mathbb{E} Y}{\\mathbb{E}{X^2} - (\\mathbb{E} X)^2} \\text{ et } b^* = \\mathbb{E} Y - a^* \\mathbb{E} X \\end{array}$$\n",
    "\n",
    "Lorsqu'on a plusieurs dimensions pour $X$, on écrit le problème d'optimisation, on cherche les coefficients $\\beta^*$ qui minimisent :\n",
    "\n",
    "$$E(\\beta)=\\sum_{i=1}^n \\left(y_i - X_i \\beta\\right)^2 = \\left \\Vert Y - X\\beta \\right \\Vert ^2$$\n",
    "\n",
    "La solution est : $\\beta^* = (X'X)^{-1}X'Y$.\n",
    "\n",
    "Ecrire une fonction qui calcule ce vecteur optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "\n",
    "Ecrire une fonction qui transforme un vecteur en une matrice diagonale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7\n",
    "\n",
    "On considère maintenant que chaque observation est pondérée par un poids $w_i$. On veut maintenant trouver le vecteur $\\beta$ qui minimise :\n",
    "\n",
    "$$E(\\beta)=\\sum_{i=1}^n w_i \\left( y_i - X_i \\beta \\right)^2 = \\left \\Vert W^{\\frac{1}{2}}(Y - X\\beta)\\right \\Vert^2$$\n",
    "\n",
    "Où $W=diag(w_1, ..., w_n)$ est la matrice diagonale. La solution est :\n",
    "\n",
    "$$\\beta_* = (X'WX)^{-1}X'WY$$.\n",
    "\n",
    "Ecrire une fonction qui calcule la solution de la régression pondérée. La fonction [ravel](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html) est utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8\n",
    "\n",
    "Ecrire une fonction qui calcule les quantités suivantes (fonctions [maximum](https://docs.scipy.org/doc/numpy/reference/generated/numpy.maximum.html), [reciprocal](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reciprocal.html#numpy.reciprocal)).\n",
    "\n",
    "$$z_i = \\frac{1}{\\max\\left( \\delta, \\left|y_i - X_i \\beta\\right|\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9\n",
    "\n",
    "On souhaite coder l'algorithme suivant :\n",
    "\n",
    "1. $w_i^{(1)} = 1$\n",
    "2. $\\beta_{(t)} = (X'W^{(t)}X)^{-1}X'W^{(t)}Y$\n",
    "3. $w_i^{(t+1)} = \\frac{1}{\\max\\left( \\delta, \\left|y_i - X_i \\beta^{(t)}\\right|\\right)}$\n",
    "4. $t = t+1$\n",
    "5. Retour à l'étape 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10\n",
    "\n",
    "Sachant les vecteurs X et Y ci-dessous:\n",
    "- vers quoi converge l'algorithme de regression linéaire ?\n",
    "- vers quoi converge l'algorithme codé à la question 9 ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = ensemble_aleatoire(10)\n",
    "Y = numpy.empty((len(ens), 1))\n",
    "Y[:,0] = ens\n",
    "X = numpy.ones((len(ens), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques explications et démonstrations\n",
    "\n",
    "Cet énoncé est inspiré de [Iteratively reweighted least squares](https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares). Cet algorithme permet notamment d'étendre la notion de médiane à des espaces vectoriels de plusieurs dimensions. On peut détermine un point $X_M$ qui minimise la quantité :\n",
    "\n",
    "$$\\sum_{i=1}^n \\left| X_i - X_M \\right |$$\n",
    "\n",
    "Nous reprenons l'algorithme décrit ci-dessus :\n",
    "\n",
    "1. $w_i^{(1)} = 1$\n",
    "2. $\\beta_{(t)} = (X'W^{(t)}X)^{-1}X'W^{(t)}Y$\n",
    "3. $w_i^{(t+1)} = \\frac{1}{\\max\\left( \\delta, \\left|y_i - X_i \\beta^{(t)}\\right|\\right)}$\n",
    "4. $t = t+1$\n",
    "5. Retour à l'étape 2.\n",
    "\n",
    "L'erreur quadratique pondéré est :\n",
    "\n",
    "$$E_2(\\beta, W) = \\sum_{i=1}^n w_i \\left\\Vert Y_i - X_i \\beta \\right\\Vert^2$$\n",
    "\n",
    "Si $w_i = \\frac{1}{\\left|y_i - X_i \\beta\\right|}$, on remarque que :\n",
    "\n",
    "$$E_2(\\beta, W) = \\sum_{i=1}^n \\frac{\\left\\Vert Y_i - X_i \\beta \\right\\Vert^2}{\\left|y_i - X_i \\beta\\right|} = \\sum_{i=1}^n \\left|y_i - X_i \\beta\\right| = E_1(\\beta)$$\n",
    "\n",
    "On retombe sur l'erreur en valeur absolue optimisée par la régression quantile. Comme l'étape 2 consiste à trouver les coefficients $\\beta$ qui minimise $E_2(\\beta, W^{(t)})$, par construction, il ressort que :\n",
    "\n",
    "$$E_1(\\beta^{(t+1)}) = E_2(\\beta^{(t+1)}, W^{(t)}) \\leqslant E_2(\\beta^{(t)}, W^{(t)}) = E_1(\\beta^{(t)})$$\n",
    "\n",
    "La suite $t \\rightarrow E_1(\\beta^{(t)})$ est suite décroissant est minorée par 0. Elle converge donc vers un minimum. Or la fonction $\\beta \\rightarrow E_1(\\beta)$ est une fonction convexe. Elle n'admet qu'un seul minimum (mais pas nécessaire un seul point atteignant ce minimum). L'algorithme converge donc vers la médiane. Le paramètre $\\delta$ est là pour éviter les erreurs de divisions par zéros et les approximations de calcul faites par l'ordinateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quelques commentaires sur le code\n",
    "\n",
    "Le symbol [@](https://www.python.org/dev/peps/pep-0465/) a été introduit par Python 3.5 et est équivalent à la fonction [numpy.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html). Les dimensions des matrices posent souvent quelques problèmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "y = numpy.array([1, 2, 3])\n",
    "M = numpy.array([[3, 4], [6, 7], [3, 3]])\n",
    "M.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "     M @ y\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, numpy considère un vecteur de taille ``(3,)`` comme un vecteur ligne ``(3,1)``. Donc l'expression suivante va marcher :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y @ M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
